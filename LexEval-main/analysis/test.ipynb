{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /vol/bitbucket/lst20/lex-\n",
      "[nltk_data]     eval/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /vol/bitbucket/lst20/lex-eval/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import os\n",
    "PATH = '/vol/bitbucket/lst20/lex-eval'\n",
    "nltk.data.path.append(os.path.join(PATH, 'nltk_data'))  # Add to path if needed\n",
    "nltk.download('punkt_tab', download_dir=os.path.join(PATH, 'nltk_data'))\n",
    "nltk.download('averaged_perceptron_tagger_eng', download_dir=os.path.join(PATH, 'nltk_data'))\n",
    "from nltk.tag import pos_tag \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.chunk import RegexpParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"the yellow cat is sleeping under the christmas tree made of roasted ducks. What a lovely christmas morning.\"\n",
    "\n",
    "# sample_text = 'Although she had planned to leave early, knowing that the traffic had been unusually heavy due to ongoing roadworks that the city council had failed to address despite numerous complaints would likely cause delays, she found herself stuck at her desk much to her frustration, , where a last-minute email from her manager who had just returned from a business trip during which he had met with several important clients whose contracts were still pending approval required her immediate attention before she could even think about packing up and heading home.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  Although/IN\n",
      "  she/PRP\n",
      "  had/VBD\n",
      "  planned/VBN\n",
      "  to/TO\n",
      "  leave/VB\n",
      "  (NP early/JJ)\n",
      "  ,/,\n",
      "  knowing/VBG\n",
      "  (PP that/IN (NP the/DT traffic/NN))\n",
      "  had/VBD\n",
      "  been/VBN\n",
      "  unusually/RB\n",
      "  (NP heavy/JJ due/JJ)\n",
      "  to/TO\n",
      "  ongoing/VBG\n",
      "  (NP roadworks/NNS)\n",
      "  (PP that/IN (NP the/DT city/NN council/NN))\n",
      "  had/VBD\n",
      "  failed/VBN\n",
      "  to/TO\n",
      "  address/VB\n",
      "  (PP despite/IN (NP numerous/JJ complaints/NNS))\n",
      "  would/MD\n",
      "  likely/RB\n",
      "  cause/VB\n",
      "  (NP delays/NNS)\n",
      "  ,/,\n",
      "  she/PRP\n",
      "  found/VBD\n",
      "  herself/PRP\n",
      "  (NP stuck/NN)\n",
      "  at/IN\n",
      "  her/PRP$\n",
      "  (NP desk/NN)\n",
      "  (NP much/JJ)\n",
      "  to/TO\n",
      "  her/PRP$\n",
      "  (NP frustration/NN)\n",
      "  ,/,\n",
      "  ,/,\n",
      "  where/WRB\n",
      "  (NP a/DT last-minute/JJ email/NN)\n",
      "  from/IN\n",
      "  her/PRP$\n",
      "  (NP manager/NN)\n",
      "  who/WP\n",
      "  had/VBD\n",
      "  just/RB\n",
      "  returned/VBN\n",
      "  (PP from/IN (NP a/DT business/NN trip/NN))\n",
      "  during/IN\n",
      "  which/WDT\n",
      "  he/PRP\n",
      "  had/VBD\n",
      "  met/VBN\n",
      "  (PP with/IN (NP several/JJ important/JJ clients/NNS))\n",
      "  whose/WP$\n",
      "  (NP contracts/NNS)\n",
      "  were/VBD\n",
      "  still/RB\n",
      "  pending/VBG\n",
      "  (NP approval/NN)\n",
      "  required/VBD\n",
      "  her/PRP$\n",
      "  (NP immediate/JJ attention/NN)\n",
      "  before/IN\n",
      "  she/PRP\n",
      "  could/MD\n",
      "  even/RB\n",
      "  think/VB\n",
      "  about/IN\n",
      "  packing/VBG\n",
      "  up/RP\n",
      "  and/CC\n",
      "  heading/VBG\n",
      "  (NP home/NN)\n",
      "  ./.) 4\n"
     ]
    }
   ],
   "source": [
    "# https://www.nltk.org/book_1ed/ch07.html#ref-chunkex-grammar\n",
    "tokens = word_tokenize(sample_text)\n",
    "# Find all parts of speech in above sentence\n",
    "tagged = pos_tag(tokens)\n",
    "\n",
    "#Extract all parts of speech from any text\n",
    "chunker = RegexpParser(\"\"\"\n",
    "                    NP: {<DT|PP$>?<JJ>*<NN|NNS>*}    # chunk determiner/possessive, adjectives and nouns\n",
    "                    PP: {<IN><NP>}                   # Chunk prepositions followed by NP\n",
    "                    VP: {<VB.*><NP|PP|CLAUSE>+$}    # Chunk verbs and their arguments\n",
    "                    CLAUSE: {<NP><VP>}              # Chunk NP, VP\n",
    "                    \"\"\")\n",
    "\n",
    "# Print all parts of speech in above sentence\n",
    "output = chunker.parse(tagged)\n",
    "print(output, output.height())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_trf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height of the parse tree: 7\n"
     ]
    }
   ],
   "source": [
    "# Process the text with spaCy\n",
    "doc = nlp(sample_text)\n",
    "\n",
    "# Function to compute the height of the parse tree\n",
    "def compute_tree_height(token):\n",
    "    if not list(token.children):  # If the token has no children, it's a leaf\n",
    "        return 1\n",
    "    else:\n",
    "        return 1 + max(compute_tree_height(child) for child in token.children)\n",
    "\n",
    "# Find the ROOT of the parse tree\n",
    "root = [token for token in doc if token.dep_ == \"ROOT\"][0]\n",
    "\n",
    "# Compute height of the parse tree\n",
    "parse_tree_height = compute_tree_height(root)\n",
    "\n",
    "# Print parse tree height\n",
    "print(f\"Height of the parse tree: {parse_tree_height}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lex-eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
